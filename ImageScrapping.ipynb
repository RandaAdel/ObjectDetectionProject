{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602b0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3996dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import os \n",
    "import base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccdc756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://www.google.com/search?q=dog&source=lnms&tbm=isch&sa=X&ved=2ahUKEwie44_AnqLpAhUhBWMBHUFGD90Q_AUoAXoECBUQAw&biw=1920&bih=947\")\n",
    "driver.maximize_window()\n",
    "time.sleep(1)\n",
    "\n",
    "#Click reject button to be able to scrape the images \n",
    "submit = driver.find_element(\"xpath\",\"//button[@class='VfPpkd-LgbsSe VfPpkd-LgbsSe-OWXEXe-k8QpJ VfPpkd-LgbsSe-OWXEXe-dgl2Hf nCP5yc AjY5Oe DuMIQc LQeN7 Nc7WLe']\").click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "#Click on an image \n",
    "#imgurl = driver.find_element(\"xpath\",'//*[@id=\"islrg\"]/div[1]/div[%s]/a[1]/div[1]/img'%(str(2))).click()\n",
    "\n",
    "urls = []\n",
    "urls_schemes = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    imgurl = driver.find_element(\"xpath\",'//*[@id=\"islrg\"]/div[1]/div[%s]/a[1]/div[1]/img'%(str(2)))\n",
    "    src_link = imgurl.get_attribute(\"src\")\n",
    "    #if((\"http\" in  src_link) and (not \"encrypted\" in src_link)):\n",
    "    urls.append(src_link)\n",
    "    urls_schemes.append(parsed_url.scheme)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5efb7e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'data',\n",
       " 'data',\n",
       " 'data',\n",
       " 'data',\n",
       " 'data',\n",
       " 'data',\n",
       " 'data',\n",
       " 'data',\n",
       " 'data']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how the pic src is saved within the webste \n",
    "\n",
    "urls_schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a24b1dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save image that is embedded in the website \n",
    "\n",
    "image_data = urls[0]\n",
    "# Extract the base64-encoded image data from the string\n",
    "image_data = image_data.split(',')[1]\n",
    "\n",
    "# Decode the base64 data into bytes\n",
    "image_bytes = base64.b64decode(image_data)\n",
    "\n",
    "#Create the \"images\" folder if it does not exist\n",
    "folder_name = \"images\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Save the image to a file in the \"images\" folder\n",
    "image_file_name = \"image_file_name.jpg\"  # Replace with the name you want to give the saved image\n",
    "image_file_path = os.path.join(folder_name, image_file_name)\n",
    "\n",
    "with open(image_file_path, \"wb\") as f:\n",
    "    f.write(image_bytes)\n",
    "\n",
    "print(\"Image saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de28c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d3bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac25fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf8ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35adbabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "967c790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To be used in case no scheme was found \n",
    "\n",
    "# from urllib.parse import urlparse\n",
    "\n",
    "# # Replace \"image_url\" with the actual image URL that you want to save\n",
    "# image_url = urls[0]\n",
    "\n",
    "# # Parse the URL to check if it has a scheme\n",
    "# parsed_url = urlparse(image_url)\n",
    "\n",
    "# # Add the \"http://\" scheme if it is missing\n",
    "# if not parsed_url.scheme:\n",
    "#     image_url = \"http://\" + image_url\n",
    "\n",
    "# print(image_url)    \n",
    "    \n",
    "# # Make a request to download the image\n",
    "# response = requests.get(image_url)\n",
    "\n",
    "# # Check if the request was successful\n",
    "# if response.status_code == 200:\n",
    "#     # Replace \"image_file_name.jpg\" with the name that you want to give the saved image\n",
    "#     with open(\"image_file_name.jpg\", \"wb\") as f:\n",
    "#         f.write(response.content)\n",
    "#     print(\"Image saved successfully!\")\n",
    "# else:\n",
    "#     print(\"Error: Could not download the image.\")\n",
    "    \n",
    "# #-------------------------------------------------------------------------------------------#\n",
    "# #Check which savinf option is the best \n",
    "\n",
    "# for indx,image_url in enumerate(urls):\n",
    "#     image = requests.get(image_url,timeout=5)\n",
    "#     if image.status_code == 200:\n",
    "#         #Create a binary stream from the binary content by Pillow to open the image\n",
    "#         with Image.open(io.BytesIO(image.content)) as image_from_web:\n",
    "#             image_from_web.save(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770066f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d468c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df0a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab25462e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18dbc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5974c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688494f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31457e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eaef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HLE\n",
    "class GoogleImageScraper():\n",
    "    def __init__(self, webdriver_path, image_path, search_key=\"cat\", number_of_images=1, headless=True, min_resolution=(0, 0), max_resolution=(1920, 1080), max_missed=10):\n",
    "        #check parameter types\n",
    "        image_path = os.path.join(image_path, search_key)\n",
    "        if (type(number_of_images)!=int):\n",
    "            print(\"[Error] Number of images must be integer value.\")\n",
    "            return\n",
    "        if not os.path.exists(image_path):\n",
    "            print(\"[INFO] Image path not found. Creating a new folder.\")\n",
    "            os.makedirs(image_path)\n",
    "            \n",
    "        #check if chromedriver is installed\n",
    "        if (not os.path.isfile(webdriver_path)):\n",
    "            is_patched = patch.download_lastest_chromedriver()\n",
    "            if (not is_patched):\n",
    "                exit(\"[ERR] Please update the chromedriver.exe in the webdriver folder according to your chrome version:https://chromedriver.chromium.org/downloads\")\n",
    "\n",
    "        for i in range(1):\n",
    "            try:\n",
    "                #try going to www.google.com\n",
    "                options = Options()\n",
    "                if(headless):\n",
    "                    options.add_argument('--headless')\n",
    "                driver = webdriver.Chrome(webdriver_path, chrome_options=options)\n",
    "                driver.set_window_size(1400,1050)\n",
    "                driver.get(\"https://www.google.com\")\n",
    "            except Exception as e:\n",
    "                #update chromedriver\n",
    "                pattern = '(\\d+\\.\\d+\\.\\d+\\.\\d+)'\n",
    "                version = list(set(re.findall(pattern, str(e))))[0]\n",
    "                is_patched = patch.download_lastest_chromedriver(version)\n",
    "                if (not is_patched):\n",
    "                    exit(\"[ERR] Please update the chromedriver.exe in the webdriver folder according to your chrome version:https://chromedriver.chromium.org/downloads\")\n",
    "\n",
    "        self.driver = driver\n",
    "        self.search_key = search_key\n",
    "        self.number_of_images = number_of_images\n",
    "        self.webdriver_path = webdriver_path\n",
    "        self.image_path = image_path\n",
    "        self.url = \"https://www.google.com/search?q=%s&source=lnms&tbm=isch&sa=X&ved=2ahUKEwie44_AnqLpAhUhBWMBHUFGD90Q_AUoAXoECBUQAw&biw=1920&bih=947\"%(search_key)\n",
    "        self.headless=headless\n",
    "        self.min_resolution = min_resolution\n",
    "        self.max_resolution = max_resolution\n",
    "        self.max_missed = max_missed\n",
    "\n",
    "    def find_image_urls(self):\n",
    "        \"\"\"\n",
    "            This function search and return a list of image urls based on the search key.\n",
    "            Example:\n",
    "                google_image_scraper = GoogleImageScraper(\"webdriver_path\",\"image_path\",\"search_key\",number_of_photos)\n",
    "                image_urls = google_image_scraper.find_image_urls()\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Gathering image links\")\n",
    "        image_urls=[]\n",
    "        count = 0\n",
    "        missed_count = 0\n",
    "        self.driver.get(self.url)\n",
    "\n",
    "        ## Add a step to pass the rejection page on google chrome \n",
    "        submit = self.driver.find_element(\"xpath\",\"//button[@class='VfPpkd-LgbsSe VfPpkd-LgbsSe-OWXEXe-k8QpJ VfPpkd-LgbsSe-OWXEXe-dgl2Hf nCP5yc AjY5Oe DuMIQc LQeN7 Nc7WLe']\").click()\n",
    "\n",
    "        time.sleep(3)\n",
    "        indx = 1\n",
    "        while self.number_of_images > count:\n",
    "            try:\n",
    "                #find and click image\n",
    "                imgurl = self.driver.find_element(By.XPATH,'//*[@id=\"islrg\"]/div[1]/div[%s]/a[1]/div[1]/img'%(str(indx)))\n",
    "                imgurl.click()\n",
    "                missed_count = 0\n",
    "            except Exception:\n",
    "                missed_count = missed_count + 1\n",
    "                if (missed_count>self.max_missed):\n",
    "                    print(\"[INFO] Maximum missed photos reached, exiting...\")\n",
    "                    break\n",
    "\n",
    "            try:\n",
    "                #select image from the popup\n",
    "                time.sleep(1)\n",
    "                #class_names = [\"n3VNCb\"]\n",
    "                class_names = [\"n3VNCb pT0Scc KAlRDb\"]\n",
    "                images = [self.driver.find_elements(By.CLASS_NAME, class_name) for class_name in class_names if len(self.driver.find_elements(By.CLASS_NAME, class_name)) != 0 ][0]\n",
    "                for image in images:\n",
    "                    #only download images that starts with http\n",
    "                    src_link = image.get_attribute(\"src\")\n",
    "                    if((\"http\" in  src_link) and (not \"encrypted\" in src_link)):\n",
    "                        print(\n",
    "                            f\"[INFO] {self.search_key} \\t #{count} \\t {src_link}\")\n",
    "                        image_urls.append(src_link)\n",
    "                        count +=1\n",
    "                        break\n",
    "            except Exception:\n",
    "                print(\"[INFO] Unable to get link\")\n",
    "\n",
    "            try:\n",
    "                #scroll page to load next image\n",
    "                if(count%3==0):\n",
    "                    self.driver.execute_script(\"window.scrollTo(0, \"+str(indx*60)+\");\")\n",
    "                element = self.driver.find_element(By.CLASS_NAME,\"mye4qd\")\n",
    "                element.click()\n",
    "                print(\"[INFO] Loading next page\")\n",
    "                time.sleep(3)\n",
    "            except Exception:\n",
    "                time.sleep(1)\n",
    "            indx += 1\n",
    "\n",
    "\n",
    "        self.driver.quit()\n",
    "        print(\"[INFO] Google search ended\")\n",
    "        return image_urls\n",
    "\n",
    "    def save_images(self,image_urls, keep_filenames):\n",
    "        print(keep_filenames)\n",
    "        #save images into file directory\n",
    "        \"\"\"\n",
    "            This function takes in an array of image urls and save it into the given image path/directory.\n",
    "            Example:\n",
    "                google_image_scraper = GoogleImageScraper(\"webdriver_path\",\"image_path\",\"search_key\",number_of_photos)\n",
    "                image_urls=[\"https://example_1.jpg\",\"https://example_2.jpg\"]\n",
    "                google_image_scraper.save_images(image_urls)\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Saving image, please wait...\")\n",
    "        for indx,image_url in enumerate(image_urls):\n",
    "            try:\n",
    "                print(\"[INFO] Image url:%s\"%(image_url))\n",
    "                search_string = ''.join(e for e in self.search_key if e.isalnum())\n",
    "                image = requests.get(image_url,timeout=5)\n",
    "                if image.status_code == 200:\n",
    "                    with Image.open(io.BytesIO(image.content)) as image_from_web:\n",
    "                        try:\n",
    "                            if (keep_filenames):\n",
    "                                #extact filename without extension from URL\n",
    "                                o = urlparse(image_url)\n",
    "                                image_url = o.scheme + \"://\" + o.netloc + o.path\n",
    "                                name = os.path.splitext(os.path.basename(image_url))[0]\n",
    "                                #join filename and extension\n",
    "                                filename = \"%s.%s\"%(name,image_from_web.format.lower())\n",
    "                            else:\n",
    "                                filename = \"%s%s.%s\"%(search_string,str(indx),image_from_web.format.lower())\n",
    "\n",
    "                            image_path = os.path.join(self.image_path, filename)\n",
    "                            print(\n",
    "                                f\"[INFO] {self.search_key} \\t {indx} \\t Image saved at: {image_path}\")\n",
    "                            image_from_web.save(image_path)\n",
    "                        except OSError:\n",
    "                            rgb_im = image_from_web.convert('RGB')\n",
    "                            rgb_im.save(image_path)\n",
    "                        image_resolution = image_from_web.size\n",
    "                        if image_resolution != None:\n",
    "                            if image_resolution[0]<self.min_resolution[0] or image_resolution[1]<self.min_resolution[1] or image_resolution[0]>self.max_resolution[0] or image_resolution[1]>self.max_resolution[1]:\n",
    "                                image_from_web.close()\n",
    "                                os.remove(image_path)\n",
    "\n",
    "                        image_from_web.close()\n",
    "            except Exception as e:\n",
    "                print(\"[ERROR] Download failed: \",e)\n",
    "                pass\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"[INFO] Downloads completed. Please note that some photos were not downloaded as they were not in the correct format (e.g. jpg, jpeg, png)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a6a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4481fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fdf16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e78b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c404fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f06bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
